{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from notebooks import config\n",
    "from utils.imgShow import imsShow\n",
    "from model import unet, unet_scales \n",
    "from utils.utils import read_scenes\n",
    "from utils.metrics import oa_binary, miou_binary\n",
    "from utils.dataloader import SceneArraySet_scales, PatchPathSet_scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 256\n",
    "higher_patch_size = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### traset\n",
    "paths_scene_tra, paths_truth_tra = config.paths_scene_tra, config.paths_truth_tra\n",
    "paths_dem_tra = config.paths_dem_tra\n",
    "# paths_dem_tra = config.paths_dem_adjust_tra\n",
    "print(f'train scenes: {len(paths_scene_tra)}')\n",
    "### valset\n",
    "paths_valset = sorted(glob(f'data/dset/valset/patch_{higher_patch_size}/*'))  ## for model prediction \n",
    "# paths_patch_valset = sorted(glob(f'data/dset/valset/patch_{patch_size}_dem_adjust/*'))\n",
    "print(f'vali patch: {len(paths_valset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load traset\n",
    "scenes_dem_arr, truths_arr = read_scenes(paths_scene_tra, \n",
    "                                            paths_truth_tra, \n",
    "                                            paths_dem_tra) \n",
    "print('traset:', len(scenes_dem_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "tra_data = SceneArraySet_scales(scenes_arr=scenes_dem_arr,    \n",
    "                          truths_arr=truths_arr,   \n",
    "                          patch_size=256,   \n",
    "                          higher_patch_size=1024,   \n",
    "                          patch_resize=True)   \n",
    "val_data = PatchPathSet_scales(paths_valset=paths_valset,   \n",
    "                          higher_patch_size=1024,  \n",
    "                          patch_size=256,  \n",
    "                          patch_resize=True)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_loader = torch.utils.data.DataLoader(tra_data, \n",
    "                                         batch_size=4, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=10)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, \n",
    "                                         batch_size=4, \n",
    "                                         num_workers=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_scales(num_bands_local=7, \n",
    "                    num_bands_global=7, \n",
    "                    patch_size=patch_size,\n",
    "                    higher_patch_size=higher_patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_loader_iter = iter(tra_loader)\n",
    "val_loader_iter = iter(val_loader)\n",
    "tra_one = next(tra_loader_iter)\n",
    "val_one = next(val_loader_iter)\n",
    "pred_local, pred_global, pred_global2local = model(tra_one[0], tra_one[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  \n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\\n",
    "                                          mode='min', factor=0.6, patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bce = nn.BCELoss()\n",
    "loss_mse = nn.MSELoss() \n",
    "\n",
    "def loss_rmse(y_pred, y_true):\n",
    "    mse = torch.mean((y_pred - y_true)**2)\n",
    "    return torch.sqrt(mse)\n",
    "\n",
    "class Loss_scales(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_global = nn.BCELoss()\n",
    "        self.loss_local = nn.MSELoss()\n",
    "    def forward(self, x_local, y_local, x_global,  y_global):\n",
    "        loss_global = self.loss_global(x_global, y_global)\n",
    "        loss_local = self.loss_local(x_local, y_local)\n",
    "        return loss_local + loss_global\n",
    "loss_scales = Loss_scales()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------train step------'''\n",
    "def train_step(x_patch,\n",
    "               y_patch,\n",
    "               x_higher_patch, \n",
    "               y_higher_patch,\n",
    "               model, \n",
    "               optimizer, \n",
    "               loss_fn):\n",
    "    optimizer.zero_grad()\n",
    "    pred_local, pred_global, _ = model(x_patch, x_higher_patch)\n",
    "    # loss = loss_fn(pred_local, y_patch.float())\n",
    "    loss = loss_fn(x_local=pred_local, \n",
    "                    y_local=y_patch.float(), \n",
    "                    x_global=pred_global, \n",
    "                    y_global=y_higher_patch.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    miou = miou_binary(pred=pred_local, truth=y_patch, device=x_patch.device)\n",
    "    oa = oa_binary(pred=pred_local, truth=y_patch, device=x_patch.device)\n",
    "    return loss, miou, oa\n",
    "'''------validation step------'''\n",
    "def val_step(x_patch,\n",
    "             y_patch,\n",
    "             x_higher_patch,\n",
    "             y_higher_patch, \n",
    "             model,\n",
    "             loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_local, pred_global, _ = model(x_patch, x_higher_patch)\n",
    "        # loss = loss_fn(pred_local, y_patch.float())\n",
    "        loss = loss_fn(x_local=pred_local, \n",
    "                       y_local=y_patch.float(), \n",
    "                       x_global=pred_global, \n",
    "                       y_global=y_higher_patch.float())\n",
    "    miou = miou_binary(pred=pred_local, truth=y_patch, device=x_patch.device)\n",
    "    oa = oa_binary(pred=pred_local, truth=y_patch, device=x_patch.device)\n",
    "    return loss, miou, oa\n",
    "\n",
    "'''------train loops------'''\n",
    "def train_loops(model,\n",
    "                loss_fn, \n",
    "                optimizer, \n",
    "                tra_loader, \n",
    "                val_loader, \n",
    "                epoches, \n",
    "                device, \n",
    "                lr_scheduler=None):\n",
    "    tra_loss_loops, tra_miou_loops, tra_oa_loops = [], [], []\n",
    "    val_loss_loops, val_miou_loops, val_oa_loops = [], [], []\n",
    "    model = model.to(device)\n",
    "    size_tra_loader = len(tra_loader)\n",
    "    size_val_loader = len(val_loader)\n",
    "    for epoch in range(epoches):\n",
    "        start = time.time()\n",
    "        tra_loss, val_loss = 0, 0\n",
    "        tra_miou, val_miou = 0, 0\n",
    "        tra_oa, val_oa = 0, 0\n",
    "        '''-----train the model-----'''\n",
    "        for x_patch, y_patch, x_higher_patch, y_higher_patch in tra_loader:\n",
    "            x_patch, y_patch, x_higher_patch, y_higher_patch = x_patch.to(device), y_patch.to(device), x_higher_patch.to(device), y_higher_patch.to(device)\n",
    "            loss, miou, oa = train_step(x_patch=x_patch, \n",
    "                                        y_patch=y_patch,\n",
    "                                        x_higher_patch=x_higher_patch,\n",
    "                                        y_higher_patch=y_higher_patch,\n",
    "                                        model=model,\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_fn=loss_fn)                                        \n",
    "            tra_loss += loss.item()\n",
    "            tra_miou += miou.item()\n",
    "            tra_oa += oa.item()\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step(tra_loss)    # if using ReduceLROnPlateau\n",
    "        '''----- validation the model: time consuming -----'''\n",
    "        for x_patch, y_patch, x_higher_patch, y_higher_patch in val_loader:\n",
    "            x_patch, y_patch, x_higher_patch, y_higher_patch = x_patch.to(device), y_patch.to(device), x_higher_patch.to(device), y_higher_patch.to(device)\n",
    "            loss, miou, oa = val_step(x_patch=x_patch, \n",
    "                                    y_patch=y_patch, \n",
    "                                    x_higher_patch=x_higher_patch, \n",
    "                                    y_higher_patch=y_higher_patch, \n",
    "                                    model=model, \n",
    "                                    loss_fn=loss_fn)            \n",
    "            val_loss += loss.item()\n",
    "            val_miou += miou.item()\n",
    "            val_oa += oa.item()\n",
    "        ## Accuracy\n",
    "        tra_loss = tra_loss/size_tra_loader\n",
    "        val_loss = val_loss/size_val_loader\n",
    "        tra_miou = tra_miou/size_tra_loader\n",
    "        val_miou = val_miou/size_val_loader\n",
    "        tra_oa = tra_oa/size_tra_loader\n",
    "        val_oa = val_oa/size_val_loader\n",
    "        tra_loss_loops.append(tra_loss); tra_miou_loops.append(tra_miou); tra_oa_loops.append(tra_oa)\n",
    "        val_loss_loops.append(val_loss); val_miou_loops.append(val_miou); val_oa_loops.append(val_oa)\n",
    "        print(f'Ep{epoch+1}: tra-> Loss:{tra_loss:.3f},Oa:{tra_oa:.3f},Miou:{tra_miou:.3f}, '\n",
    "                f'val-> Loss:{val_loss:.3f},Oa:{val_oa:.3f}, Miou:{val_miou:.3f},time:{time.time()-start:.1f}s')\n",
    "        ## show the result\n",
    "        if (epoch+1)%10 == 0:\n",
    "            model.eval()\n",
    "            sam_index = random.randrange(len(val_data))\n",
    "            patch, ptruth, higher_patch, higher_ptruth = val_data[sam_index]\n",
    "            patch, ptruth = torch.unsqueeze(patch.float(), 0).to(device), ptruth.to(device)\n",
    "            higher_patch, higher_ptruth = torch.unsqueeze(higher_patch.float(), 0).to(device), torch.unsqueeze(higher_ptruth.float(), 0).to(device)\n",
    "            pred_local, pred_global, pred_global2local = model(patch, higher_patch)\n",
    "            ## convert to numpy and plot\n",
    "            patch = patch[0].to('cpu').detach().numpy().transpose(1,2,0)\n",
    "            pdem = patch[:,:, -1]\n",
    "            pred_patch = pred_local[0].to('cpu').detach().numpy()\n",
    "            pred_global2local = pred_global2local[0].to('cpu').detach().numpy()\n",
    "            ptruth = ptruth.to('cpu').detach().numpy()\n",
    "            pred_higher_patch = pred_global[0].to('cpu').detach().numpy()\n",
    "            higher_patch = higher_patch[0].to('cpu').detach().numpy().transpose(1,2,0)\n",
    "            higher_ptruth = higher_ptruth.to('cpu').detach().numpy()\n",
    "            imsShow([higher_patch, pred_higher_patch, patch, pdem, pred_global2local, pred_patch, ptruth], \n",
    "                    clip_list = (2,0,2,2,0,0,0),\n",
    "                    img_name_list=['input_higher_patch', 'pred_higher_patch', 'input_patch', \n",
    "                                   'pdem', 'pred_global2local', 'pred', 'truth'],                     \n",
    "                    figsize=(20,3))\n",
    "    metrics = {'tra_loss':tra_loss_loops, 'tra_miou':tra_miou_loops, 'tra_oa': tra_oa_loops, \n",
    "                    'val_loss': val_loss_loops, 'val_miou': val_miou_loops, 'val_oa': val_oa_loops}\n",
    "    return metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')  \n",
    "metrics = train_loops(model=model,  \n",
    "                      epoches=200,  \n",
    "                      loss_fn=loss_scales,  \n",
    "                      optimizer=optimizer,  \n",
    "                      lr_scheduler=lr_scheduler,   \n",
    "                      tra_loader=tra_loader,   \n",
    "                      val_loader=val_loader,  \n",
    "                      device=device)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model saving\n",
    "# model_name = 'u2net'\n",
    "### net_name = 'deeplabv3plus'\n",
    "### net_name = 'deeplabv3plus_mb2'\n",
    "# path_save = f'model/trained/{model_name}_{patch_size}/{model_name}.pth'\n",
    "# torch.save(model.state_dict(), path_save)   ## save weights of the trained model \n",
    "# # # model.load_state_dict(torch.load(path_save, weights_only=True))  # load the weights of the trained model\n",
    "# # # ## metrics saving\n",
    "# path_metrics = f'model/trained/{model_name}_{patch_size}/{model_name}_metrics.csv'\n",
    "# metrics_df = pd.DataFrame(metrics)\n",
    "# metrics_df.to_csv(path_metrics, index=False, sep=',')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glanet-luo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

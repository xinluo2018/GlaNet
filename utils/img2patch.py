### author: xin luo, 
### create: 2021.3.19
### des: 1. remote sensing image to patches and 
#        2. patches to remote sensing image

import numpy as np
import random
import cv2

class img2patch():
    def __init__(self, img, patch_size, edge_overlay, drop_last=False):
        ''' edge_overlay = left overlay or, right overlay
        edge_overlay should be an even number. '''
        if edge_overlay % 2 != 0:
            raise ValueError('Argument edge_overlay should be an even number')
        self.drop_last = drop_last
        self.edge_overlay = edge_overlay        
        self.patch_size = patch_size
        self.img = img[:,:,np.newaxis] if len(img.shape) == 2 else img
        self.img_row = img.shape[0]
        self.img_col = img.shape[1]
        self.num_patch_row = np.nan    # valid when call toPatch
        self.num_patch_col = np.nan
        self.start_list = []       #  

    def toPatch(self):
        '''
        des: 
            convert img to patches. 
        return: 
            patch_list, contains all generated patches.
            start_list, contains all start positions(row, col) of the generated patches. 
        '''
        patch_list = []
        patch_step = self.patch_size - self.edge_overlay
        ## the padding method: (1) to ensure all image area is covered (the last patch covers the padding area); 
        ##                     (2) make the same edge removing for all patches
        img_expand = np.pad(self.img, ((self.edge_overlay, self.patch_size),
                                          (self.edge_overlay, self.patch_size), (0,0)), 'constant')
        self.num_patch_row = (img_expand.shape[0]-self.edge_overlay)//patch_step
        self.num_patch_col = (img_expand.shape[1]-self.edge_overlay)//patch_step
        if self.drop_last:
            self.num_patch_row -= 1
            self.num_patch_col -= 1
        for i in range(self.num_patch_row):
            for j in range(self.num_patch_col):
                patch_list.append(img_expand[i*patch_step:i*patch_step+self.patch_size,
                                                        j*patch_step:j*patch_step+self.patch_size, :])
                self.start_list.append([i*patch_step-self.edge_overlay, j*patch_step-self.edge_overlay])
        return patch_list

    def higher_patch_crop(self, higher_patch_size):
        '''
        des: 
            crop the higher-scale patch (centered by the given low-scale patch)
                (!!note: the toPatch() should be firstly called when use higher_patch_crop())
        input:
            img, np.array, the original image
            patch_size, int, the lower-scale patch size
            crop_size, int, the higher-scale patch size
            start_list, list, the start position (row,col) corresponding to the original image (generated by the toPatch function)
        return: 
            higher_patch_list, list, contains higher-scale patches corresponding to the lower-scale patches.
        '''
        higher_patch_list = []
        radius_bias = higher_patch_size//2-self.patch_size//2
        img_expand = np.pad(self.img, ((self.edge_overlay, self.patch_size), \
                                            (self.edge_overlay, self.patch_size), (0,0)), 'constant')
        img_expand_higher = np.pad(img_expand, ((radius_bias, radius_bias), \
                                            (radius_bias, radius_bias), (0,0)), 'constant')
        start_list_new = list(np.array(self.start_list)+self.edge_overlay+radius_bias)
        for start_i in start_list_new:
            higher_row_start, higher_col_start = start_i[0]-radius_bias, start_i[1]-radius_bias
            higher_patch = img_expand_higher[higher_row_start:higher_row_start+higher_patch_size, \
                                                            higher_col_start:higher_col_start+higher_patch_size,:]
            higher_patch_list.append(higher_patch)
        return higher_patch_list

    def toImage(self, patch_list):
        '''
        des: 
            merge patches into one image. 
            (!!note: the toPatch() should be firstly called when use toImage())
        '''
        if self.drop_last:
            raise ValueError('The drop_last is set to True, cannot merge patches to full image')
        patch_list = [patch[self.edge_overlay//2:-self.edge_overlay//2, self.edge_overlay//2:-self.edge_overlay//2,:]
                                                        for patch in patch_list]
        patch_list = [np.hstack((patch_list[i*self.num_patch_col:i*self.num_patch_col+self.num_patch_col]))
                                                        for i in range(int(self.num_patch_row))]
        img_array = np.vstack(patch_list)
        img_array = img_array[self.edge_overlay//2:self.img_row+self.edge_overlay//2, \
            self.edge_overlay//2:self.img_col+self.edge_overlay//2,:]
        return img_array


class crop2patch():
    '''  
    des: crop image to specific-size patch.
    args:
      img: np.array()
      channel_first: True or False.
    '''
    def __init__(self, img, channel_first=False):
      self.channel_first = channel_first
      if self.channel_first: 
        self.img = np.transpose(img, (1,2,0)) 
      else:
        self.img = img

    def toSize(self, size=(256, 256)):
      ''' 
        des: randomly crop corresponding to specific size
        input:
          size: tuble/list, (height, width)
        return: patch, the cropped patch from the image.
      '''
      start_h = random.randint(0, self.img.shape[0]-size[0])
      start_w = random.randint(0, self.img.shape[1]-size[1])
      patch = self.img[start_h:start_h+size[0], 
                       start_w:start_w+size[1],:]
      if self.channel_first:
        patch = np.transpose(patch, (2,0,1))
      return patch

    def toScales(self, scales=(2048, 512, 256), resize = True):
        ''' 
        des: randomly crop multiple-scale patches (from high to low) from remote sensing image.
        input:
            scales: tuple or list (high scale -> low scale)
        return: patches_group_down: list of multiscale patches.
        '''
        height, width = self.img.shape[:-1]
        if height<scales[0] or width<scales[0]:
          raise Exception('The input scale overpass the size of image!')
        patches_group = []
        patch_high = self.toSize(size=(scales[0], scales[0]))
        patches_group.append(patch_high)
        for scale in scales[1:]:
            start_offset = (scales[0]-scale)//2
            patch_lower = patch_high[start_offset:start_offset+scale, 
                                     start_offset:start_offset+scale, :]
            patches_group.append(patch_lower)
        if resize:            
            for i, patch in enumerate(patches_group[:-1]):
                patch_down = cv2.resize(patch, dsize=(scales[-1], scales[-1]), \
                                    interpolation=cv2.INTER_LINEAR)
                patches_group[i] = patch_down      
        if self.channel_first:
          patches_group = [np.transpose(patch_down, (2,0,1)) for patch_down in patches_group]
        return patches_group


